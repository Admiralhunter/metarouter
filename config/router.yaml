server:
  host: "0.0.0.0"
  port: 8000

lm_studio:
  base_url: "http://localhost:1234"
  timeout: 300
  refresh_interval: 60  # Refresh model list every 60 seconds

router:
  model: "microsoft/phi-4"          # Router model (keep loaded in LM Studio)
  prefer_loaded_bonus: 50           # Score bonus for already-loaded models
  auto_load_models: true            # Allow loading new models automatically

performance_tracking:
  enabled: true                     # Learn from real inference metrics
  sample_size: 10                   # Track last N inferences per model

benchmarks:
  enabled: true                     # Include benchmark scores in routing context
  cache_ttl_hours: 24               # Refresh benchmark data every 24 hours
  auto_fetch_missing: true          # Fetch when encountering unknown models
  api_timeout: 30                   # Timeout for Artificial Analysis API

logging:
  level: "INFO"
  log_routing_decisions: true
